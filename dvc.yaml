stages:
  train:
    cmd: bash -c "source scripts/mlflow_env.local.sh && scripts/ensure_mlflow_env.sh
      && python -m src.training"
    deps:
    - data/processed/weatherAUS_processed.csv
    - src/data_preparation.py
    - src/training.py
    outs:
    - models/pipeline.joblib
  evaluate:
    cmd: bash -c "source scripts/mlflow_env.local.sh && scripts/ensure_mlflow_env.sh
      && python -m src.evaluation"
    deps:
    - data/processed/weatherAUS_processed.csv
    - models/pipeline.joblib
    - src/data_preparation.py
    - src/evaluation.py
    metrics:
    - metrics/eval.json:
        cache: false
  predict:
    cmd: bash -c "source scripts/mlflow_env.local.sh && scripts/ensure_mlflow_env.sh
      && python -m src.predict_batch"
    deps:
    - data/raw/weatherAUS.csv
    - models/pipeline.joblib
    - src/predict_batch.py
    outs:
    - outputs/predictions_daily.csv
  preprocess:
    cmd: python -m src.data_preparation
    deps:
    - data/raw/weatherAUS.csv
    - src/data_preparation.py
    outs:
    - data/processed/weatherAUS_processed.csv
